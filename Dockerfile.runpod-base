# Use the image with the oldest version of CUDA while maintaining PyTorch >=2.0.
# This is because some RunPod Community Cloud hosts have older NVIDIA driver versions. What matters on the host is the NVIDIA driver version, not the CUDA version. NVIDIA drivers are only compatible up to a certain version of CUDA.
FROM runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04
ARG MAIN
ARG HNDR_EMBEDDER_MODE
ENV HNDR_EMBEDDER_MODE=$HNDR_EMBEDDER_MODE

RUN pip install huggingface_hub
COPY $MAIN/download_model.py /tmp/download_model.py
RUN python /tmp/download_model.py

RUN curl -fLSs --output /usr/bin/runpodctl https://github.com/runpod/runpodctl/releases/download/v1.14.2/runpodctl-linux-amd64
RUN chmod +x /usr/bin/runpodctl

COPY --from=telegraf /usr/bin/telegraf /telegraf
COPY runpod/telegraf.conf /
COPY --from=grafana/promtail /usr/bin/promtail /promtail
COPY promtail.yaml /

RUN curl -fLSs https://deb.nodesource.com/setup_21.x | bash - && apt install -yq nodejs

WORKDIR /app

# https://docs.rapids.ai/install
# This will also install CuPy.
RUN pip install \
    --extra-index-url=https://pypi.nvidia.com \
    cudf-cu11==24.4.* dask-cudf-cu11==24.4.* cuml-cu11==24.4.* \
    cugraph-cu11==24.4.* cuspatial-cu11==24.4.* cuproj-cu11==24.4.* \
    cuxfilter-cu11==24.4.* cucim-cu11==24.4.* pylibraft-cu11==24.4.* \
    raft-dask-cu11==24.4.* cuvs-cu11==24.4.*
COPY requirements.txt .
RUN pip install -r requirements.txt
# TODO HACK to disable TQDM from trashing our logs. (TQDM_DISABLE=1 doesn't seem to work.)
RUN sed -i 's%tqdm(%(lambda x, **o: x)(%' /usr/local/lib/python3.10/dist-packages/FlagEmbedding/bge_m3.py

COPY package.json .
RUN npm i

COPY tsconfig.json .
COPY common common
COPY $MAIN $MAIN
RUN npx tsc

ENV MAIN=$MAIN
ENV NODE_NO_WARNINGS=1
ENV NODE_OPTIONS='--enable-source-maps --max-old-space-size=16384 --stack-trace-limit=1024'
ENV PYTHONUNBUFFERED=1
ENV TQDM_DISABLE=1
COPY runpod/docker.entrypoint.sh .
CMD bash docker.entrypoint.sh
